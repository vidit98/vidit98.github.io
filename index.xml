<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Vidit</title><link>https://vidit98.github.io/</link><atom:link href="https://vidit98.github.io/index.xml" rel="self" type="application/rss+xml"/><description>Vidit</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate><image><url>https://vidit98.github.io/media/icon_hu98bb4d687085840bfd0de566152e579e_170750_512x512_fill_lanczos_center_3.png</url><title>Vidit</title><link>https://vidit98.github.io/</link></image><item><title>Example Talk</title><link>https://vidit98.github.io/talk/example-talk/</link><pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate><guid>https://vidit98.github.io/talk/example-talk/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click on the &lt;strong>Slides&lt;/strong> button above to view the built-in slides feature.
&lt;/div>
&lt;/div>
&lt;p>Slides can be added in a few ways:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Create&lt;/strong> slides using Wowchemy&amp;rsquo;s &lt;a href="https://wowchemy.com/docs/managing-content/#create-slides" target="_blank" rel="noopener">&lt;em>Slides&lt;/em>&lt;/a> feature and link using &lt;code>slides&lt;/code> parameter in the front matter of the talk file&lt;/li>
&lt;li>&lt;strong>Upload&lt;/strong> an existing slide deck to &lt;code>static/&lt;/code> and link using &lt;code>url_slides&lt;/code> parameter in the front matter of the talk file&lt;/li>
&lt;li>&lt;strong>Embed&lt;/strong> your slides (e.g. Google Slides) or presentation video on this page using &lt;a href="https://wowchemy.com/docs/writing-markdown-latex/" target="_blank" rel="noopener">shortcodes&lt;/a>.&lt;/li>
&lt;/ul>
&lt;p>Further event details, including &lt;a href="https://wowchemy.com/docs/writing-markdown-latex/" target="_blank" rel="noopener">page elements&lt;/a> such as image galleries, can be added to the body of this page.&lt;/p></description></item><item><title>PAIR DIFFUSION: Object-Level Image Editing with Structure-and-Appearance Paired Diffusion Models</title><link>https://vidit98.github.io/publication/conference-paper/pair_diff/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>https://vidit98.github.io/publication/conference-paper/pair_diff/</guid><description>&lt;!--
&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
-->
&lt;!-- Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --></description></item><item><title>Interactive Neural Painting</title><link>https://vidit98.github.io/publication/conference-paper/inp/</link><pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate><guid>https://vidit98.github.io/publication/conference-paper/inp/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;!-- Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --></description></item><item><title>Implementing Custom Modules in Pytorch</title><link>https://vidit98.github.io/post/impl/</link><pubDate>Thu, 27 Jun 2019 00:00:00 +0000</pubDate><guid>https://vidit98.github.io/post/impl/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>There are many posts and codes on how to build your own deep neural network using built-in functions and modules such as torch.nn.Conv2d or F.relu etc.but what if you want to design a completely new module for your network. In this blog post, we will learn about things that you need to keep in mind while implementing your own module and some common errors that might drive you up the wall.&lt;/p>
&lt;p>&lt;a href="https://medium.com/@vidit.goel9816/implementing-custom-modules-in-pytorch-b1c18edab048" target="_blank" rel="noopener">Medium Article ðŸ‘‰&lt;/a>&lt;/p>
&lt;!--
## Get Started
- ðŸ‘‰ [**Create a new site**](https://wowchemy.com/templates/)
- ðŸ“š [**Personalize your site**](https://wowchemy.com/docs/)
- ðŸ’¬ [Chat with the **Wowchemy community**](https://discord.gg/z8wNYzb) or [**Hugo community**](https://discourse.gohugo.io)
- ðŸ¦ Twitter: [@wowchemy](https://twitter.com/wowchemy) [@GeorgeCushen](https://twitter.com/GeorgeCushen) [#MadeWithWowchemy](https://twitter.com/search?q=%23MadeWithWowchemy&amp;src=typed_query)
- ðŸ’¡ [Request a **feature** or report a **bug** for _Wowchemy_](https://github.com/wowchemy/wowchemy-hugo-themes/issues)
- â¬†ï¸ **Updating Wowchemy?** View the [Update Tutorial](https://wowchemy.com/docs/hugo-tutorials/update/) and [Release Notes](https://wowchemy.com/updates/) --></description></item><item><title>Visual Recognition using Graph</title><link>https://vidit98.github.io/post/vis_reco/</link><pubDate>Thu, 27 Jun 2019 00:00:00 +0000</pubDate><guid>https://vidit98.github.io/post/vis_reco/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>Convolution neural networks have been a great success in visual recognition tasks. This article particularly focuses on semantic segmentation. The logic behind using CNN is that images have a sense of locality that is, the pixels which are near to each other are more related. CNNs are able to capture this by convolution operations and the local region that comes into consideration (formally known as receptive field) depends on the kernel size. There are also long-range dependencies in an image which can help in visual recognition tasks. For that the concept is to stack may convolution layers which will theoretically increase the receptive field. So now both long range and short range dependencies are taken into account, put the network on the training and you get the results easy right!&lt;/p>
&lt;p>But I am sure you are well aware that not many times things match in theory and practical. Recently a paper ( by Luo, Wenjie, et al.) was published which showed that receptive fields do not grow linearly with the number of convolution layers moreover they are severely limited. Furthermore, the receptive field depends on various other factors such as initialization schemes. So what is the solution?&lt;/p>
&lt;p>Find the solution &lt;a href="https://towardsdatascience.com/visual-recognition-using-graphs-9c446005736e" target="_blank" rel="noopener">Medium Article&lt;/a>&lt;/p>
&lt;!--
## Get Started
- ðŸ‘‰ [**Create a new site**](https://wowchemy.com/templates/)
- ðŸ“š [**Personalize your site**](https://wowchemy.com/docs/)
- ðŸ’¬ [Chat with the **Wowchemy community**](https://discord.gg/z8wNYzb) or [**Hugo community**](https://discourse.gohugo.io)
- ðŸ¦ Twitter: [@wowchemy](https://twitter.com/wowchemy) [@GeorgeCushen](https://twitter.com/GeorgeCushen) [#MadeWithWowchemy](https://twitter.com/search?q=%23MadeWithWowchemy&amp;src=typed_query)
- ðŸ’¡ [Request a **feature** or report a **bug** for _Wowchemy_](https://github.com/wowchemy/wowchemy-hugo-themes/issues)
- â¬†ï¸ **Updating Wowchemy?** View the [Update Tutorial](https://wowchemy.com/docs/hugo-tutorials/update/) and [Release Notes](https://wowchemy.com/updates/) --></description></item><item><title>An example preprint / working paper</title><link>https://vidit98.github.io/publication/preprint/</link><pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate><guid>https://vidit98.github.io/publication/preprint/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;p>Supplementary notes can be added here, including &lt;a href="https://wowchemy.com/docs/writing-markdown-latex/" target="_blank" rel="noopener">code, math, and images&lt;/a>.&lt;/p></description></item><item><title>Example Project</title><link>https://vidit98.github.io/project/example/</link><pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate><guid>https://vidit98.github.io/project/example/</guid><description>&lt;p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p>
&lt;p>Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p>
&lt;p>Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p>
&lt;p>Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p>
&lt;p>Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p></description></item><item><title>External Project</title><link>https://vidit98.github.io/project/external-project/</link><pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate><guid>https://vidit98.github.io/project/external-project/</guid><description/></item><item><title>An example journal article</title><link>https://vidit98.github.io/publication/journal-article/</link><pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate><guid>https://vidit98.github.io/publication/journal-article/</guid><description>&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Create your slides in Markdown - click the &lt;em>Slides&lt;/em> button to check out the example.
&lt;/div>
&lt;/div>
&lt;p>Supplementary notes can be added here, including &lt;a href="https://wowchemy.com/docs/writing-markdown-latex/" target="_blank" rel="noopener">code, math, and images&lt;/a>.&lt;/p></description></item><item><title/><link>https://vidit98.github.io/admin/config.yml</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://vidit98.github.io/admin/config.yml</guid><description/></item></channel></rss>